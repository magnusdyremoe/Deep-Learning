{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW6.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wvvqLTIsGQVu"},"source":["#HW6: Variational Autoencoder\n","In this homework, we will explore how to develop a Variational Autoencoder (VAE). As a dataset, we will use the MNIST dataset.\n","In developing the VAE we also explore how to develop an ad-hoc layer and a nonstandard training step.\n"]},{"cell_type":"markdown","metadata":{"id":"9eLnJcZVMYuD"},"source":["##Load data\n","We load the MNIST dataset, using tf.keras.datasets. We will use the same code used in HW5."]},{"cell_type":"code","metadata":{"id":"sM4gErqXAviU","executionInfo":{"status":"ok","timestamp":1621516262390,"user_tz":-120,"elapsed":3813,"user":{"displayName":"Alessandro Sperduti","photoUrl":"","userId":"08278600788437334823"}}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1bL48MXBY6Q"},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","\n","\n","x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n","x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n","\n","x_valid, y_valid = x_train[:10000], y_train[:10000]\n","x_train, y_train = x_train[10000:],y_train[10000:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XJHlLHfWGTXT"},"source":["##[TO COMPLETE] Exercise 6.1: Variational Autoencoder: reparameterization trick\n","To implement a VAE we have to define 2 main parts: the Encoder, and the Decoder.\n","Let's start by the Encoder that computes an encoding of the input from which it computes the mean and the average of the sample distribution.\n","Once we have these two statistics, we have to implement the sampling phase. Keras does not provide any predefined method to perform this operation, therefore we have to define it. With the aim to be consistent with the layer-composition paradigm used by Keras in defining a model, we define the Sampling layer as a new layer.\n","\n","To do this we define a new class that inherits from the layer base class tf.keras.layers that is used as base class for all the layers defined in Keras. Specifically, from this class we are interested in overriding the *call* method, that is the one that is called when a layer is exploited by the model, and where the operations executed by the layer are defined.\n","\n","In our case, the Sampling layer has in input the mean and the log-variance, and it has to compute the sample $z$ from them by exploiting the reparameterization trick:\n","$$\n","z=z_{mean} + exp(z_{var}/2) * \\epsilon\n","$$\n","The reparameterization trick is used in VAE because it actually helps in the backpropagation process. Specifically, $\\epsilon$ actually reparameterizes our VAE network. This allows the mean and log-variance vectors to still remain as the learnable parameters of the network while  maintaining the stochasticity of the entire system via epsilon.\n","\n","**[To complete]**: complete the code defining the Sampling layer that implements the reparametrization trick.\n","\n","**Hint**: to generate random values from a normal distribution you can use the keras [tf.keras.backend.random_normal](https://www.tensorflow.org/api_docs/python/tf/keras/backend/random_normal) method.\n"]},{"cell_type":"code","metadata":{"id":"bTzQzilTBCLv"},"source":["class Sampling(tf.keras.layers.Layer):\n","   \n","    def call(self, inputs):\n","        #[TO COMPLETE] compute and return z\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wk0EeyP2SGbV"},"source":["##[TO COMPLETE] Exercise 6.2: Encoder\n","Now we can define the encoder. Let's use 3 dense layers (similarly to what we did in HW5), and then use the obtained encoding to compute z_mean and z_var, by using two different dense layers. Finally, we use the Sampling layer to compute the sample $z$. Note that we define the latent_dim (that is the dimension of $z$) to 2. This choice is made to make possible to represent the results easily.\n","\n","**[TO COMPLETE]**: complete the code defining a deep encoder and the Dense layers that model z_mean and z_var. Explain your choice for what concerns the number of layers, the layers sizes and the activation functions. (Insert motivations about your choice into cells immediately below this one.)"]},{"cell_type":"code","metadata":{"id":"gpJ9MJ4eBFzR"},"source":["latent_dim = 2\n","\n","encoder_inputs = tf.keras.layers.Input(shape=(784,))\n","x = #[TO COMPLETE]\n","#...[TO COMPLETE]...\n","z_mean =  #[TO COMPLETE] Hint: size would be = latent_dim\n","z_var =  #[TO COMPLETE] Hint: size would be = latent_dim\n","z = Sampling()([z_mean, z_var])\n","encoder = tf.keras.Model(encoder_inputs, [z_mean, z_var, z], name=\"encoder\")\n","encoder.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0yCOHUF6BMSS"},"source":["##[TO COMPLETE] Exercise 6.3: Decoder\n","Then we have to define the decoder part. It takes in input $z$ that \"decodes\" as an image in the input space. The architecture of the decoder should be specular to the encoder architecture, i.e. 2 layers of the same dimensions of ones in the encoder, but occurring in the reverse order.\n","\n","**[TO COMPLETE]**: define the decoder. Explain in this cell your choice for what concerns the number of layers, the layers sizes, and the activation functions (in particular, for what concerns the last layer)."]},{"cell_type":"code","metadata":{"id":"uXgmAGujBNZz"},"source":["latent_inputs = keras.Input(shape=(latent_dim,))\n","x = #[TO COMPLETE]\n","#...[TO COMPLETE]...\n","decoder_outputs = tf.keras.layers.Dense(784, .... )(x) #[TO COMPLETE]\n","\n","decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n","decoder.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9wG7SGDCT_o-"},"source":["##[TO COMPLETE] Exercise 6.4: Training\n","Now we can define the VAE, but since it is a generative model, we have to define an ad-hoc training phase. Specifically, we have to manage the two losses used for this model. Indeed the parameters of a VAE are trained via two loss functions: a reconstruction loss, that forces the decoded samples to match the initial inputs, and a regularization loss that helps to learn  a well-formed latent space, and to reduce overfitting. The regularization loss is handled with the Kullback-Liebler Divergence. While for the reconstruction loss we are supposed to use the negative log-likelihood. Keras, however, does not support it natively, so to make the exercise simple, we will use as a proxy the binary cross-entropy to compare each feature of a data point to the value in the reconstructed output.\n","\n","Therefore, we have to define a class that inherits from [keras.model](https://www.tensorflow.org/api_docs/python/tf/keras/Model), and overrides the [training_step method](https://www.tensorflow.org/api_docs/python/tf/keras/Model#train_step), that allows to define a custom training logic.\n","\n","**[TO COMPLETE]** implement the reconstruction loss and the KL-loss."]},{"cell_type":"code","metadata":{"id":"Dq-2RlHABVSJ"},"source":["class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def train_step(self, data):\n","        if isinstance(data, tuple):\n","            data = data[0]\n","        with tf.GradientTape() as tape:\n","            z_mean, z_var, z = encoder(data)\n","            reconstruction = decoder(z)\n","\n","\n","            reconstruction_loss = #[TO COMPLETE]\n","            kl_loss = #[TO COMPLETE]\n","\n","\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        return {\n","            \"loss\": total_loss,\n","            \"reconstruction_loss\": reconstruction_loss,\n","            \"kl_loss\": kl_loss,\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PImJi2TxavXi"},"source":["Let's now train the VAE model using Adam as optimizer."]},{"cell_type":"code","metadata":{"id":"ysYUfYfFEsua"},"source":["vae = VAE(encoder, decoder)\n","vae.compile(optimizer=keras.optimizers.Adam())\n","vae.fit(x_train, epochs=30, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jddDtR-9a8bC"},"source":["##[TO COMPLETE] Exercise 6.5: Model Analysis\n","Now we can plot an example of the data generation by using the decoder part. Since we used a 2D latent space let's generate sevral possibile 2D $\\hat{z}$ samples and pass them to our decoder. With the $scale$ parameter we can define the interval from where the entries of $\\hat{z}$ are chosen, and with parameter $n$ it is possibile to define how many samples are generated.  "]},{"cell_type":"code","metadata":{"id":"hr1A4m8-EAvW"},"source":["def plot_latent(encoder, decoder, scale=2.0, n = 30):\n","     \n","    digit_size = 28\n","    figsize = 15\n","    figure = np.zeros((digit_size * n, digit_size * n))\n","\n","    grid_x = np.linspace(-scale, scale, n)\n","    grid_y = np.linspace(-scale, scale, n)[::-1]\n","\n","    for i, yi in enumerate(grid_y):\n","        for j, xi in enumerate(grid_x):\n","            z_sample = np.array([[xi, yi]])\n","            x_decoded = decoder.predict(z_sample)\n","            digit = x_decoded[0].reshape(digit_size, digit_size)\n","            figure[\n","                i * digit_size : (i + 1) * digit_size,\n","                j * digit_size : (j + 1) * digit_size,\n","            ] = digit\n","\n","    plt.figure(figsize=(figsize, figsize))\n","    start_range = digit_size // 2\n","    end_range = n * digit_size + start_range + 1\n","    pixel_range = np.arange(start_range, end_range, digit_size)\n","    sample_range_x = np.round(grid_x, 1)\n","    sample_range_y = np.round(grid_y, 1)\n","    plt.xticks(pixel_range, sample_range_x)\n","    plt.yticks(pixel_range, sample_range_y)\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.imshow(figure, cmap=\"Greys_r\")\n","    plt.show()\n","\n","\n","plot_latent(encoder, decoder, 2.0, 30) \n","\n","#[TO COMPLETE] explore with different \"scale\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-UKjEPDcKFD"},"source":["Let's finally check how the various digits have been rapresented in the latent space by the VAE."]},{"cell_type":"code","metadata":{"id":"B_BeApdhEbML"},"source":["def plot_label_clusters(encoder, decoder, data, labels):\n","    z_mean, _, _ = encoder.predict(data)\n","    plt.figure(figsize=(12, 10))\n","    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n","    plt.colorbar()\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.show()\n","\n","plot_label_clusters(encoder, decoder, x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LfOoqu6z2QLV"},"source":["**[TO COMPLETE]** Discuss the obtained plots, and  explore how the hyper-parameters of the VAE (number of layers, layer sizes, etc.) influence the final result. Insert your discussion into cells immediately below this one."]}]}